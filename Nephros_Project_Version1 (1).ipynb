{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c350ce5b",
      "metadata": {
        "id": "c350ce5b"
      },
      "source": [
        "\n",
        "# Nephros: Kidney Disease Detection\n",
        "\n",
        "This notebook demonstrates the process of classifying kidney diseases using the Kidney CT Scan Dataset. It covers:\n",
        "\n",
        "1. Dataset Preparation\n",
        "2. Data Preprocessing\n",
        "3. Model Development\n",
        "4. Model Evaluation\n",
        "5. Conclusions and Next Steps\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "693d0f86",
      "metadata": {
        "id": "693d0f86"
      },
      "source": [
        "## 1. Dataset Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "These first steps can be run to download the dataset. Be sure to have the Kaggle API downloaded already!"
      ],
      "metadata": {
        "id": "8bKpsr1rdVZi"
      },
      "id": "8bKpsr1rdVZi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "665e9f3c",
      "metadata": {
        "id": "665e9f3c"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.upload()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0650980",
      "metadata": {
        "id": "f0650980"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d anima890/kidney-ct-scan\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72b47ce9",
      "metadata": {
        "id": "72b47ce9"
      },
      "outputs": [],
      "source": [
        "!unzip -o kidney-ct-scan.zip -d kidney_ct_scan\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "926aeff1",
      "metadata": {
        "id": "926aeff1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Path to the extracted dataset\n",
        "dataset_path = '/content/kidney_ct_scan'\n",
        "print(os.listdir(dataset_path))  # Check what files or folders exist\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e1a6593",
      "metadata": {
        "id": "7e1a6593"
      },
      "outputs": [],
      "source": [
        "csv_path = os.path.join(dataset_path, 'kidneyData.csv')  # Update with the actual name if needed\n",
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv(csv_path)\n",
        "print(data.head())  # Preview the first few rows\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51912247",
      "metadata": {
        "id": "51912247"
      },
      "source": [
        "## 2. Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the next few steps, you can inspect and play around with the data. Set up directories in order to properly set up the data for later steps."
      ],
      "metadata": {
        "id": "OFVOXO8Odd_o"
      },
      "id": "OFVOXO8Odd_o"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3b845ae",
      "metadata": {
        "id": "b3b845ae"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define the path to the dataset\n",
        "dataset_csv_path = '/content/kidney_ct_scan/kidneyData.csv'  # Path to the CSV file\n",
        "base_dir = '/content/data'  # Base directory for organized data\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(dataset_csv_path)\n",
        "\n",
        "# Preview the data\n",
        "print(data.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db458767",
      "metadata": {
        "id": "db458767"
      },
      "outputs": [],
      "source": [
        "# Update the path column to point to the correct directory\n",
        "data['path'] = data['path'].str.replace('/content/data', '/content/kidney_ct_scan')\n",
        "\n",
        "# Verify the updated paths\n",
        "print(data['path'].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc7abaaf",
      "metadata": {
        "id": "bc7abaaf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# List the contents of the main dataset directory\n",
        "dataset_path = '/content/kidney_ct_scan'\n",
        "print(os.listdir(dataset_path))  # Show the main folder contents\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f62954fb",
      "metadata": {
        "id": "f62954fb"
      },
      "outputs": [],
      "source": [
        "for folder in os.listdir(dataset_path):\n",
        "    folder_path = os.path.join(dataset_path, folder)\n",
        "    if os.path.isdir(folder_path):\n",
        "        print(f\"Folder: {folder}\")\n",
        "        print(f\"Sample Files: {os.listdir(folder_path)[:5]}\")  # Show first 5 files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6db23c2f",
      "metadata": {
        "id": "6db23c2f"
      },
      "outputs": [],
      "source": [
        "subfolder_path = os.path.join(dataset_path, 'CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone')\n",
        "print(os.listdir(subfolder_path)[:10])  # Show first 10 files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2223ff85",
      "metadata": {
        "id": "2223ff85"
      },
      "outputs": [],
      "source": [
        "nested_folder_path = os.path.join(subfolder_path, 'CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone')\n",
        "print(os.listdir(nested_folder_path)[:10])  # Show first 10 items in the nested folder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cc30beb",
      "metadata": {
        "id": "0cc30beb"
      },
      "outputs": [],
      "source": [
        "# Update the paths to include the nested folder structure\n",
        "data['path'] = data['path'].str.replace(\n",
        "    '/content/data/CT KIDNEY DATASET Normal, CYST, TUMOR and STONE',\n",
        "    '/content/kidney_ct_scan/CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone/CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone'\n",
        ")\n",
        "\n",
        "# Verify updated paths\n",
        "print(data['path'].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4984162",
      "metadata": {
        "id": "b4984162"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "nested_folder_path = '/content/kidney_ct_scan/CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone/CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone'\n",
        "for class_name in os.listdir(nested_folder_path):\n",
        "    class_folder = os.path.join(nested_folder_path, class_name)\n",
        "    if os.path.isdir(class_folder):\n",
        "        print(f\"Class: {class_name}\")\n",
        "        print(f\"Sample files: {os.listdir(class_folder)[:5]}\")  # Show first 5 files\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, that I have found the fact that the data has a nested folder, I move on to making sure that the data is clean (there are no corrupt or missing images)"
      ],
      "metadata": {
        "id": "r-ZB1Pjld3Vm"
      },
      "id": "r-ZB1Pjld3Vm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47c91423",
      "metadata": {
        "id": "47c91423"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Path to the nested folder\n",
        "nested_folder_path = '/content/kidney_ct_scan/CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone/CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone'\n",
        "\n",
        "# Create a new DataFrame with correct paths\n",
        "file_paths = []\n",
        "labels = []\n",
        "\n",
        "for class_name in os.listdir(nested_folder_path):\n",
        "    class_folder = os.path.join(nested_folder_path, class_name)\n",
        "    if os.path.isdir(class_folder)\n",
        "        for file_name in os.listdir(class_folder):\n",
        "            file_paths.append(os.path.join(class_folder, file_name))\n",
        "            labels.append(class_name)  # Use the folder name as the label\n",
        "\n",
        "# Create a DataFrame\n",
        "data_cleaned = pd.DataFrame({'path': file_paths, 'Class': labels})\n",
        "\n",
        "# Verify the new DataFrame\n",
        "print(data_cleaned.head())\n",
        "print(f\"Number of files: {len(data_cleaned)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c60c927c",
      "metadata": {
        "id": "c60c927c"
      },
      "outputs": [],
      "source": [
        "missing_files = []\n",
        "for path in data_cleaned['path']:\n",
        "    if not os.path.exists(path):\n",
        "        missing_files.append(path)\n",
        "\n",
        "print(f\"Number of missing files: {len(missing_files)}\")\n",
        "print(f\"Sample missing files: {missing_files[:5]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f3be9e6",
      "metadata": {
        "id": "9f3be9e6"
      },
      "outputs": [],
      "source": [
        "dataset_path = '/content/kidney_ct_scan/CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone/CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this version due to a limited availability to computational resources, I will be taking a subset of the data and splitting it into training, validation, and test sets."
      ],
      "metadata": {
        "id": "Na85mh4YeJwz"
      },
      "id": "Na85mh4YeJwz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c41d84e3",
      "metadata": {
        "id": "c41d84e3"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "def create_subset(input_dir, output_dir, fraction=0.2, target_size=(224, 224)):\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    for class_name in os.listdir(input_dir):\n",
        "        class_dir = os.path.join(input_dir, class_name)\n",
        "        if not os.path.isdir(class_dir):\n",
        "            continue\n",
        "\n",
        "        output_class_dir = os.path.join(output_dir, class_name)\n",
        "        os.makedirs(output_class_dir, exist_ok=True)\n",
        "\n",
        "        file_paths = [os.path.join(class_dir, f) for f in os.listdir(class_dir)]\n",
        "        sampled_files = random.sample(file_paths, int(len(file_paths) * fraction))\n",
        "\n",
        "        for file_path in sampled_files:\n",
        "            with Image.open(file_path) as img:\n",
        "                img = img.resize(target_size)\n",
        "                img.save(os.path.join(output_class_dir, os.path.basename(file_path)))\n",
        "\n",
        "# Create a subset of the data\n",
        "create_subset(\n",
        "    dataset_path,\n",
        "    '/content/kidney_ct_scan_subset',\n",
        "    fraction=0.2  # Use 20% of the data\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb5f3d57",
      "metadata": {
        "id": "bb5f3d57"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "import shutil\n",
        "\n",
        "def split_dataset(input_dir, output_dir, train_frac=0.6, val_frac=0.2, test_frac=0.2):\n",
        "    # Ensure output directories exist\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    train_dir = os.path.join(output_dir, 'train')\n",
        "    val_dir = os.path.join(output_dir, 'val')\n",
        "    test_dir = os.path.join(output_dir, 'test')\n",
        "\n",
        "    os.makedirs(train_dir, exist_ok=True)\n",
        "    os.makedirs(val_dir, exist_ok=True)\n",
        "    os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "    # Process each class\n",
        "    for class_name in os.listdir(input_dir):\n",
        "        class_dir = os.path.join(input_dir, class_name)\n",
        "        if not os.path.isdir(class_dir):\n",
        "            continue\n",
        "\n",
        "        # List all files in the class directory\n",
        "        files = os.listdir(class_dir)\n",
        "\n",
        "        # Split files into train and temp (val + test)\n",
        "        train_files, temp_files = train_test_split(files, test_size=(1 - train_frac), random_state=42)\n",
        "\n",
        "        # Further split temp into val and test\n",
        "        val_files, test_files = train_test_split(\n",
        "            temp_files,\n",
        "            test_size=(test_frac / (val_frac + test_frac)),\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "        # Copy files to their respective directories\n",
        "        for file_set, target_dir in zip([train_files, val_files, test_files], [train_dir, val_dir, test_dir]):\n",
        "            class_output_dir = os.path.join(target_dir, class_name)\n",
        "            os.makedirs(class_output_dir, exist_ok=True)\n",
        "            for file_name in file_set:\n",
        "                shutil.copy(os.path.join(class_dir, file_name), os.path.join(class_output_dir, file_name))\n",
        "\n",
        "# Usage\n",
        "split_dataset(\n",
        "    '/content/kidney_ct_scan_subset',  # Input dataset path\n",
        "    '/content/kidney_ct_scan_split',  # Output dataset path\n",
        "    train_frac=0.6,                   # 60% training\n",
        "    val_frac=0.2,                     # 20% validation\n",
        "    test_frac=0.2                     # 20% test\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68976ce9",
      "metadata": {
        "id": "68976ce9"
      },
      "source": [
        "## 3. Model Development"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, I play around with different machine learning techniques to improve my model. I first implement transfer learning for the pre-trained model MobileNetV2. Then, I use different mechanisms like fine tuning the model by freezing and unfreezing layers of the CNN, adjusting the learning rate, and playing with the batch size when training the model."
      ],
      "metadata": {
        "id": "u7QdXgojfZW9"
      },
      "id": "u7QdXgojfZW9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78140e5e",
      "metadata": {
        "id": "78140e5e"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "val_test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/kidney_ct_scan_split/train',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_generator = val_test_datagen.flow_from_directory(\n",
        "    '/content/kidney_ct_scan_split/val',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3001f031",
      "metadata": {
        "id": "3001f031"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.4),\n",
        "    Dense(4, activation='softmax')  # Adjust for the number of classes\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85f4f6bb",
      "metadata": {
        "id": "85f4f6bb"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=50,\n",
        "    callbacks=[early_stopping]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a27a50e7",
      "metadata": {
        "id": "a27a50e7"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "test_generator = val_test_datagen.flow_from_directory(\n",
        "    '/content/kidney_ct_scan_split/test',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "predictions = model.predict(test_generator)\n",
        "y_pred = np.argmax(predictions, axis=1)\n",
        "y_true = test_generator.classes\n",
        "\n",
        "print(classification_report(y_true, y_pred, target_names=test_generator.class_indices.keys()))\n",
        "print(confusion_matrix(y_true, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01b47e76",
      "metadata": {
        "id": "01b47e76"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Dropout(0.3),  # Add dropout to the first convolutional block\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Dropout(0.4),  # Add dropout to the second convolutional block\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),  # Add dropout before the final Dense layer\n",
        "    Dense(4, activation='softmax')  # 4 classes\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "391e94a9",
      "metadata": {
        "id": "391e94a9"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Dropout(0.4),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu', kernel_regularizer=l2(0.01)),  # Add L2 regularization\n",
        "    Dropout(0.5),\n",
        "    Dense(4, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "870c234c",
      "metadata": {
        "id": "870c234c"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5,  # Stop training if val_loss doesn't improve for 5 epochs\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=50,\n",
        "    callbacks=[early_stopping]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac606c24",
      "metadata": {
        "id": "ac606c24"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "\n",
        "# Compute class weights\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(train_generator.classes),\n",
        "    y=train_generator.classes\n",
        ")\n",
        "class_weights = dict(enumerate(class_weights))\n",
        "\n",
        "# Apply class weights during training\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=50,\n",
        "    class_weight=class_weights,  # Apply class weights here\n",
        "    callbacks=[early_stopping]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54ef168a",
      "metadata": {
        "id": "54ef168a"
      },
      "outputs": [],
      "source": [
        "# Reinitialize train and validation generators with smaller batch size\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/kidney_ct_scan_split/train',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=16,  # Reduced batch size\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_generator = val_test_datagen.flow_from_directory(\n",
        "    '/content/kidney_ct_scan_split/val',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=16,  # Match the batch size for validation\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Retrain the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=50,\n",
        "    class_weight=class_weights,  # Retain class weights\n",
        "    callbacks=[early_stopping]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca7eed20",
      "metadata": {
        "id": "ca7eed20"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "# Use a learning rate scheduler to reduce the learning rate on a plateau\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,  # Reduce learning rate by half\n",
        "    patience=3,  # Wait 3 epochs before reducing\n",
        "    min_lr=1e-6  # Minimum learning rate\n",
        ")\n",
        "\n",
        "# Recompile the model with an initial lower learning rate\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=1e-4),  # Start with a lower learning rate\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Retrain the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=50,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=[early_stopping, reduce_lr]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b748aed",
      "metadata": {
        "id": "6b748aed"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Load MobileNetV2 with pretrained weights\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze all layers in the base model initially\n",
        "base_model.trainable = False\n",
        "\n",
        "# Add custom layers on top\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(4, activation='softmax')  # 4 output classes\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23050cbf",
      "metadata": {
        "id": "23050cbf"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=10,  # Train for a few epochs with frozen base layers\n",
        "    class_weight=class_weights,\n",
        "    callbacks=[early_stopping]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbf4008e",
      "metadata": {
        "id": "dbf4008e"
      },
      "outputs": [],
      "source": [
        "# Unfreeze the last few layers of the base model\n",
        "base_model.trainable = True\n",
        "for layer in base_model.layers[:-50]:  # Freeze all layers except the last 50\n",
        "    layer.trainable = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "691c0c29",
      "metadata": {
        "id": "691c0c29"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=Adam(learning_rate=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ded91434",
      "metadata": {
        "id": "ded91434"
      },
      "outputs": [],
      "source": [
        "history_fine_tune = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=20,  # Fine-tune for more epochs\n",
        "    class_weight=class_weights,\n",
        "    callbacks=[early_stopping, reduce_lr]  # Use early stopping and learning rate scheduler\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a7dcc9d",
      "metadata": {
        "id": "8a7dcc9d"
      },
      "outputs": [],
      "source": [
        "# Evaluate the fine-tuned model\n",
        "loss, accuracy = model.evaluate(test_generator)\n",
        "print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "458b1e8f",
      "metadata": {
        "id": "458b1e8f"
      },
      "outputs": [],
      "source": [
        "# Unfreeze more layers in the base model\n",
        "base_model.trainable = True\n",
        "for layer in base_model.layers[:-100]:  # Freeze all layers except the last 100\n",
        "    layer.trainable = False\n",
        "\n",
        "# Recompile with an even smaller learning rate\n",
        "model.compile(optimizer=Adam(learning_rate=1e-6), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Retrain the model\n",
        "history_fine_tune_more = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=20,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=[early_stopping, reduce_lr]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f3412f8",
      "metadata": {
        "id": "9f3412f8"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Recreate the ImageDataGenerator\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\n",
        "# Path to your test dataset directory\n",
        "test_dir = '/content/kidney_ct_scan_split/test'\n",
        "\n",
        "# Reinitialize test_generator\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(224, 224),  # Same size used during training\n",
        "    batch_size=16,          # Use the batch size you had before\n",
        "    class_mode='categorical',\n",
        "    shuffle=False           # Important for evaluation\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c56a9dd4",
      "metadata": {
        "id": "c56a9dd4"
      },
      "outputs": [],
      "source": [
        "loss, accuracy = model.evaluate(test_generator)\n",
        "print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c885d62",
      "metadata": {
        "id": "6c885d62"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255.0,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.3,\n",
        "    height_shift_range=0.3,\n",
        "    shear_range=0.3,\n",
        "    zoom_range=0.3,\n",
        "    horizontal_flip=True,\n",
        "    brightness_range=[0.8, 1.2],\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/kidney_ct_scan_split/train',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b1a6d96",
      "metadata": {
        "id": "2b1a6d96"
      },
      "outputs": [],
      "source": [
        "val_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    '/content/kidney_ct_scan_split/val',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    '/content/kidney_ct_scan_split/test',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d287c36",
      "metadata": {
        "id": "4d287c36"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# Early Stopping\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',  # Monitor validation loss\n",
        "    patience=5,          # Stop training after 5 epochs of no improvement\n",
        "    restore_best_weights=True  # Restore weights from the best epoch\n",
        ")\n",
        "\n",
        "# Learning Rate Reduction\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',  # Monitor validation loss\n",
        "    factor=0.1,          # Reduce learning rate by a factor of 10\n",
        "    patience=3,          # Wait 3 epochs of no improvement before reducing\n",
        "    min_lr=1e-7,         # Set a minimum learning rate\n",
        "    verbose=1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b291d06",
      "metadata": {
        "id": "9b291d06"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=20,\n",
        "    callbacks=[early_stopping, reduce_lr]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80cc5734",
      "metadata": {
        "id": "80cc5734"
      },
      "outputs": [],
      "source": [
        "# Training generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    'kidney_ct_scan_split/train',  # Update with your training dataset path\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,  # Increased batch size\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Validation generator\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    'kidney_ct_scan_split/val',  # Update with your validation dataset path\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,  # Match batch size to training\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Test generator\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    'kidney_ct_scan_split/test',  # Update with your test dataset path\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,  # Match batch size to training\n",
        "    class_mode='categorical'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f0f0eb0",
      "metadata": {
        "id": "1f0f0eb0"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=20,  # Adjust as needed\n",
        "    callbacks=[early_stopping, reduce_lr]  # Include your existing callbacks\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f156d7c3",
      "metadata": {
        "id": "f156d7c3"
      },
      "outputs": [],
      "source": [
        "loss, accuracy = model.evaluate(test_generator)\n",
        "print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0235a097",
      "metadata": {
        "id": "0235a097"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, min_lr=1e-6)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c22cbf39",
      "metadata": {
        "id": "c22cbf39"
      },
      "outputs": [],
      "source": [
        "# Training generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    'kidney_ct_scan_split/train',  # Update with your training dataset path\n",
        "    target_size=(224, 224),\n",
        "    batch_size=64,  # Increased batch size\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Validation generator\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    'kidney_ct_scan_split/val',  # Update with your validation dataset path\n",
        "    target_size=(224, 224),\n",
        "    batch_size=64,  # Match batch size to training\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Test generator\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    'kidney_ct_scan_split/test',  # Update with your test dataset path\n",
        "    target_size=(224, 224),\n",
        "    batch_size=64,  # Match batch size to training\n",
        "    class_mode='categorical'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66b3fa94",
      "metadata": {
        "id": "66b3fa94"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4),  # Start with a higher learning rate\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a969937",
      "metadata": {
        "id": "7a969937"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss',\n",
        "                               patience=5,\n",
        "                               restore_best_weights=True)\n",
        "\n",
        "history = model.fit(train_generator,\n",
        "                    validation_data=val_generator,\n",
        "                    epochs=20,\n",
        "                    callbacks=[reduce_lr, early_stopping])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd9e1d23",
      "metadata": {
        "id": "dd9e1d23"
      },
      "source": [
        "## 4. Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I now evaluate my model using my test set. I get a test loss of 0.22 and an accuracy of around 93 percent."
      ],
      "metadata": {
        "id": "8qYHjY07gD9S"
      },
      "id": "8qYHjY07gD9S"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94f1a7b1",
      "metadata": {
        "id": "94f1a7b1"
      },
      "outputs": [],
      "source": [
        "loss, accuracy = model.evaluate(test_generator)\n",
        "print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, I save the model."
      ],
      "metadata": {
        "id": "tm1LOu6GgO_n"
      },
      "id": "tm1LOu6GgO_n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a48f1747",
      "metadata": {
        "id": "a48f1747"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Define the directory where you want to save the model\n",
        "save_dir = '/content/saved_model'\n",
        "os.makedirs(save_dir, exist_ok=True)  # Create the directory if it doesn't exist\n",
        "\n",
        "# Save the model with the .keras extension\n",
        "model.save(os.path.join(save_dir, 'my_model.keras'))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa2e25ed",
      "metadata": {
        "id": "fa2e25ed"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Download the saved model\n",
        "files.download('/content/saved_model/my_model.keras')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}